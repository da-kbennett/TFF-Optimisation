{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from scipy.stats import poisson\n",
    "from scipy.stats import norm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import sasoptpy as so\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "\n",
    "pd.set_option('display.max_columns', 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import telegraph players and prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_columns(csv_file1, column1, csv_file2, column2):\n",
    "    df1 = pd.read_csv(csv_file1)\n",
    "    df2 = pd.read_csv(csv_file2)\n",
    "    \n",
    "    merged_df = df1.merge(df2, left_on=column1, right_on=column2)\n",
    "    counter = len(merged_df)\n",
    "    \n",
    "    if counter > 0:\n",
    "        # Get the column names of £m in csv_file2 and Position in csv_file2\n",
    "        column_m = '£m' if '£m' in df2.columns else 'm'  # Handle potential encoding differences\n",
    "        column_position = 'Position' if 'Position' in df2.columns else 'Position'  # Handle potential encoding differences\n",
    "\n",
    "        # Update tff_value and sky_pos with the corresponding values from £m and Position columns in csv_file2\n",
    "        for _, row in merged_df.iterrows():\n",
    "            tff_id_value = row[column1]\n",
    "            m_value = row[column_m]\n",
    "            position_value = row[column_position]\n",
    "            \n",
    "            df1.loc[df1[column1] == tff_id_value, 'tff_value'] = m_value\n",
    "            \n",
    "            # Check if Position is equal to \"STR\" in csv_file2\n",
    "            if position_value == \"STR\":\n",
    "                df1.loc[df1[column1] == tff_id_value, 'sky_pos'] = \"FOR\"\n",
    "            else:\n",
    "                df1.loc[df1[column1] == tff_id_value, 'sky_pos'] = position_value\n",
    "\n",
    "        # Set empty 'tff_value' cells to 20.0\n",
    "        empty_tff_cells = df1['tff_value'].isnull() | (df1['tff_value'] == '')\n",
    "        df1.loc[empty_tff_cells, 'tff_value'] = 20.0\n",
    "\n",
    "        # Save the updated DataFrame back to csv_file1\n",
    "        df1.to_csv(csv_file1, index=False)\n",
    "    \n",
    "    return counter\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_directory = r'../data'\n",
    "\n",
    "    csv_file1 = os.path.join(data_directory, \"prior_player_data.csv\")\n",
    "    column1 = \"fpl_code\"  # Use the correct header name for column L\n",
    "    \n",
    "    csv_file2 = os.path.join(data_directory, \"TFF_players.csv\")\n",
    "    column2 = \"ID\"  # Use the correct header name for column B\n",
    "\n",
    "    result = compare_columns(csv_file1, column1, csv_file2, column2)\n",
    "    print(f\"Number of matching values: {result}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixture Generating Funtions\n",
    "Generate ticker for visualization and optimization, based on the live fixture info from the Premier League API and any custom fixture timings and probabilities set by the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate matchday ticker dataframe, team_fixtures\n",
    "def generate_ticker(gw_range=None, exclude_teams=None, custom_fixtures=None, extra_fixtures=None, generate_all_dataframes=False):\n",
    "\n",
    "    # Infer fixture difficulties\n",
    "    team_priors = pd.read_csv(f'../data/team_priors.csv')\n",
    "    team_priors['h_off'] = round(team_priors['bl_g_for'] * team_priors['home_adv_g'],2)\n",
    "    team_priors['h_def'] = round(team_priors['bl_g_against'] / team_priors['home_adv_g'],2)\n",
    "    team_priors['h_gd'] = team_priors['h_off'] - team_priors['h_def']\n",
    "    team_priors['a_off'] = round(team_priors['bl_g_for'] / team_priors['home_adv_g'],2)\n",
    "    team_priors['a_def'] = round(team_priors['bl_g_against'] * team_priors['home_adv_g'],2)\n",
    "    team_priors['a_gd'] = team_priors['a_off'] - team_priors['a_def']\n",
    "\n",
    "    # Get fixtures and team data from pl api\n",
    "    r = requests.get('https://fantasy.premierleague.com/api/bootstrap-static/')\n",
    "    fpl_data = r.json()\n",
    "    team_data = pd.DataFrame(fpl_data['teams'])\n",
    "    team_data = team_data[['id', 'short_name']].rename(columns={\"id\": \"team_id\"})\n",
    "    team_data = team_data.replace('NFO', 'FOR')\n",
    "    r = requests.get('https://fantasy.premierleague.com/api/fixtures/')\n",
    "    fixtures_data = r.json()\n",
    "    fixtures_data = pd.DataFrame(fixtures_data)\n",
    "    fixtures_data = fixtures_data.drop('stats', axis=1)\n",
    "    fixtures_data = fixtures_data[fixtures_data['started'] != True]\n",
    "    # fixtures_data.to_csv('../data/fixtures_test_all.csv')\n",
    "    fixtures_data = fixtures_data[fixtures_data['started'] == False]\n",
    "    fixtures_data['gw'] = fixtures_data['event'].astype(int)\n",
    "    fixtures_data['kickoff_time'] = pd.to_datetime(fixtures_data['kickoff_time'])\n",
    "    fixtures_data['datetime'] = fixtures_data['kickoff_time'].dt.tz_convert('UTC').dt.tz_localize(None)\n",
    "    fixtures_data['date_str'] = fixtures_data['datetime'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "    fixtures_data['time_str'] = fixtures_data['datetime'].dt.strftime('%H:%M')\n",
    "    fixtures_data = pd.merge(fixtures_data, team_data, left_on='team_a', right_on='team_id', how='left').rename(columns={\"short_name\": \"team_a_name\", \"team_id\": \"team_a_id\"})\n",
    "    fixtures_data = pd.merge(fixtures_data, team_data, left_on='team_h', right_on='team_id', how='left').rename(columns={\"short_name\": \"team_h_name\", \"team_id\": \"team_h_id\"})\n",
    "\n",
    "    # Add customized fixtures to fixtures table\n",
    "    fixtures_data.loc[:,'customized'] = False\n",
    "    fixtures_data['custom_dates'] = [[] for _ in range(len(fixtures_data))]\n",
    "    fixtures_data['custom_probs'] = [[] for _ in range(len(fixtures_data))]\n",
    "    if custom_fixtures is not None:\n",
    "        custom_fixtures['added_to_ticker'] = False\n",
    "        for index, row in custom_fixtures.iterrows():\n",
    "            h = custom_fixtures.loc[index,'home_team']\n",
    "            a = custom_fixtures.loc[index,'away_team']\n",
    "            listy = fixtures_data.index[(fixtures_data['team_h_name'] == h) & (fixtures_data['team_a_name'] == a)].to_list()\n",
    "            # if the fixture to be added isn't in the fixtures to be played, add it\n",
    "            if listy != []:\n",
    "                i = listy[0]\n",
    "                fixtures_data.at[i, 'customized'] = True\n",
    "                fixtures_data.at[i, 'custom_dates'] = custom_fixtures.loc[index,'dates']\n",
    "                fixtures_data.at[i, 'custom_probs'] = custom_fixtures.loc[index,'probabilities']\n",
    "                custom_fixtures.at[index, 'added_to_ticker'] = True\n",
    "\n",
    "    # Drop rows not in gameweek range\n",
    "    if gw_range is not None:\n",
    "        mask = fixtures_data['gw'].isin(gw_range)\n",
    "        fixtures_data = fixtures_data[mask]\n",
    "\n",
    "    # Generate ticker\n",
    "    natural_fix_dates = sorted(fixtures_data['date_str'].unique())\n",
    "    custom_fix_dates = []\n",
    "    if custom_fixtures is not None:\n",
    "        for i, x in custom_fixtures.iterrows():\n",
    "            custom_fix_dates += (custom_fixtures.loc[i, 'dates'])\n",
    "    unique_dates = sorted(natural_fix_dates + custom_fix_dates)\n",
    "    unique_dates = sorted(list(set(unique_dates)))\n",
    "    team_fixtures = team_data.assign(**dict.fromkeys(unique_dates, ''))\n",
    "    old_date = None\n",
    "    old_datetime = None\n",
    "    for index, row in fixtures_data.iterrows():\n",
    "        new_date = row['date_str']\n",
    "        new_datetime = row['datetime']\n",
    "        away_team = row['team_a_name']\n",
    "        home_team = row['team_h_name'].lower()\n",
    "        if old_date != new_date or (row['datetime'] == old_datetime and first_fix):\n",
    "            away_team += '!'\n",
    "            home_team += '!'\n",
    "            first_fix = True\n",
    "        else:\n",
    "            first_fix = False\n",
    "        team_fixtures.loc[team_fixtures['short_name'] == row['team_h_name'], row['date_str']] = away_team\n",
    "        team_fixtures.loc[team_fixtures['short_name'] == row['team_a_name'], row['date_str']] = home_team\n",
    "        old_date = new_date\n",
    "        old_datetime = new_datetime\n",
    "    copied_natural_fixtures = team_fixtures.copy()\n",
    "    # Add the custom fixtures to the ticker, deleting their 'natural' placement\n",
    "    # NB: only fixtures that have yet to be played can be added\n",
    "    if custom_fixtures is not None:\n",
    "        for index, row in fixtures_data.iterrows():\n",
    "            if row['customized']:\n",
    "                team_fixtures.loc[team_fixtures['short_name'] == row['team_h_name'], row['date_str']] = ''\n",
    "                team_fixtures.loc[team_fixtures['short_name'] == row['team_a_name'], row['date_str']] = ''\n",
    "                for i, x in enumerate(row['custom_probs']):\n",
    "                    if x == 1:\n",
    "                        prob_str = ''\n",
    "                    elif x == 0:\n",
    "                        break\n",
    "                    else:\n",
    "                        prob_str = '*' + str(int(x*100)) + '%' \n",
    "                    date = row['custom_dates'][i]      \n",
    "                    away_team = row['team_a_name'] + '!' + prob_str\n",
    "                    home_team = row['team_h_name'].lower() + '!' + prob_str\n",
    "                    if team_fixtures.loc[team_fixtures['short_name'] == row['team_h_name'], date].to_list()[0] != '':\n",
    "                        away_team = '\\n' + away_team\n",
    "                    if team_fixtures.loc[team_fixtures['short_name'] == row['team_a_name'], date].to_list()[0] != '':\n",
    "                        home_team = '\\n' + home_team\n",
    "                    team_fixtures.loc[team_fixtures['short_name'] == row['team_h_name'], date] += away_team\n",
    "                    team_fixtures.loc[team_fixtures['short_name'] == row['team_a_name'], date] += home_team\n",
    "        # Add those fixtures which aren't included in the natural fixtures\n",
    "        if False in custom_fixtures['added_to_ticker'].tolist():\n",
    "            extra_custom_fixtures = custom_fixtures.loc[custom_fixtures['added_to_ticker'] == False]\n",
    "            for index, row in extra_custom_fixtures.iterrows():\n",
    "                for i, x in enumerate(row['probabilities']):\n",
    "                    if x == 1:\n",
    "                        prob_str = ''\n",
    "                    else:\n",
    "                        prob_str = '*' + str(int(x*100)) + '%' \n",
    "                    date = row['dates'][i]      \n",
    "                    away_team = row['away_team'] + '!' + prob_str\n",
    "                    home_team = row['home_team'].lower() + '!' + prob_str\n",
    "                    if team_fixtures.loc[team_fixtures['short_name'] == row.loc['home_team'], date].to_list() != []:\n",
    "                        if team_fixtures.loc[team_fixtures['short_name'] == row.loc['home_team'], date].to_list()[0] != '':\n",
    "                            away_team = '\\n' + away_team\n",
    "                    if team_fixtures.loc[team_fixtures['short_name'] == row.loc['away_team'], date].to_list() != []:\n",
    "                        if team_fixtures.loc[team_fixtures['short_name'] == row.loc['away_team'], date].to_list()[0] != '':\n",
    "                            home_team = '\\n' + home_team\n",
    "                    prev1 = team_fixtures.loc[team_fixtures['short_name'] == row.loc['home_team'], date] + away_team\n",
    "                    prev2 = team_fixtures.loc[team_fixtures['short_name'] == row.loc['away_team'], date] + home_team\n",
    "                    team_fixtures.loc[team_fixtures['short_name'] == row.loc['home_team'], date] = prev1\n",
    "                    team_fixtures.loc[team_fixtures['short_name'] == row.loc['away_team'], date] = prev2\n",
    "                    custom_fixtures.loc[index, 'added_to_ticker'] = True\n",
    "\n",
    "    # Generate matchday mapping to tff gw, fpl gw, date, and day of week\n",
    "    weekdays = []\n",
    "    matchdays = []\n",
    "    tff_gw_list = []\n",
    "    fpl_gw_list = []\n",
    "    tff_gw_df = pd.read_csv('../data/tff_gw_starts_2324.csv')\n",
    "    fpl_gw_df = pd.read_csv('../data/fpl_gw_starts_2324.csv')\n",
    "    tff_gw_date = tff_gw_df.loc[0,'start_date']\n",
    "    fpl_gw_date = fpl_gw_df.loc[0,'start_date']\n",
    "    fpl_gw_index = 0\n",
    "    tff_gw_index = 0\n",
    "    # loop through matchdays\n",
    "    for i, x in enumerate(unique_dates):\n",
    "        new_day = str(datetime.strptime(unique_dates[i], '%Y-%m-%d %H:%M').date().weekday())\n",
    "        weekdays.append(new_day)\n",
    "        matchdays.append(i+1)\n",
    "        # while the date of the current matchday is later than that of the proposed tff gw, proceed to the date of the next tff gw\n",
    "        while x >= tff_gw_date:\n",
    "            broken = False\n",
    "            if tff_gw_index > len(tff_gw_df)-1:\n",
    "                broken = True\n",
    "                break\n",
    "            tff_gw_index += 1\n",
    "            tff_gw_date = tff_gw_df.loc[tff_gw_index-1, 'start_date']\n",
    "        if broken:\n",
    "            tff_gw = tff_gw + 1\n",
    "        else:\n",
    "            tff_gw = tff_gw_df.loc[tff_gw_index-1, 'gameweek']-1\n",
    "        tff_gw_list.append(tff_gw)\n",
    "        # while the date of the current matchday is later than that of the proposed fpl gw, proceed to the date of the next fpl gw\n",
    "        while x >= fpl_gw_date:\n",
    "            broken = False\n",
    "            if fpl_gw_index > len(fpl_gw_df)-1:\n",
    "                broken = True\n",
    "                break\n",
    "            fpl_gw_index += 1\n",
    "            fpl_gw_date = fpl_gw_df.loc[fpl_gw_index-1, 'start_date']\n",
    "        if broken:\n",
    "            fpl_gw = fpl_gw + 1\n",
    "        else:\n",
    "            fpl_gw = fpl_gw_df.loc[fpl_gw_index-1, 'gameweek']-1\n",
    "        fpl_gw_list.append(fpl_gw)\n",
    "    data = {'unique_dates': unique_dates,\n",
    "            'weekday': weekdays,\n",
    "            'matchday': matchdays,\n",
    "            'tff_gw': tff_gw_list,\n",
    "            'fpl_gw': fpl_gw_list\n",
    "            }\n",
    "    md_map = pd.DataFrame(data)\n",
    "    date_0 = md_map.loc[0,'unique_dates']\n",
    "    date_0 = datetime.strptime(date_0, '%Y-%m-%d %H:%M').date()\n",
    "    for i, col in md_map.iterrows():\n",
    "        date_1 = md_map.loc[i,'unique_dates']\n",
    "        date_1 = datetime.strptime(date_1, '%Y-%m-%d %H:%M').date()\n",
    "        delta = int((date_1 - date_0).days)\n",
    "        md_map.loc[i,'days_elapsed'] = delta\n",
    "\n",
    "    # Generate dataframes for all possible fixture permutations for stochastic optimization, assuming all fixtures are independent\n",
    "    if generate_all_dataframes and extra_fixtures is not None:\n",
    "        uncertain_fixtures = extra_fixtures.drop(extra_fixtures[extra_fixtures.probability == 1].index)\n",
    "        my_list = uncertain_fixtures.probability.tolist()\n",
    "        # Assume all fixtures are independent\n",
    "        n_uncert_fix = len(my_list)\n",
    "        number_of_permutations = 2**(n_uncert_fix)\n",
    "        fix_permutation_dict = {}\n",
    "        for i in range(number_of_permutations):\n",
    "            fixture_key = f'permutation_{i+1}'\n",
    "            permutation_string = format(i, f'0{n_uncert_fix}b')\n",
    "            df = copied_natural_fixtures.copy()\n",
    "            likelihood = 1\n",
    "            for i, x in enumerate(permutation_string):\n",
    "                if bool(int(x)):\n",
    "                    away_team = uncertain_fixtures.loc[i,'away_team']\n",
    "                    home_team = uncertain_fixtures.loc[i,'home_team']\n",
    "                    df.loc[df['short_name'] == home_team, uncertain_fixtures.loc[i,'date']] = away_team\n",
    "                    df.loc[df['short_name'] == away_team, uncertain_fixtures.loc[i,'date']] = home_team.lower()\n",
    "                    likelihood = likelihood * uncertain_fixtures.loc[i,'probability']\n",
    "                else:\n",
    "                    likelihood = likelihood * (1-uncertain_fixtures.loc[i,'probability'])\n",
    "            fix_permutation_dict[fixture_key] = {'df': df, 'likelihood': likelihood}\n",
    "    else:\n",
    "        fix_permutation_dict = None\n",
    "\n",
    "    fixtures_df = team_fixtures.copy()\n",
    "\n",
    "    # Drop excluded teams\n",
    "    if exclude_teams is not None:\n",
    "        for i in exclude_teams:\n",
    "            team_fixtures = team_fixtures[team_fixtures.short_name != i]\n",
    "\n",
    "    # Add gameweek superheader\n",
    "    date_to_gw = fixtures_data[['date_str','gw']].drop_duplicates()\n",
    "    headers = list(team_fixtures.columns.values)\n",
    "    tff_gw_header = []\n",
    "    fpl_gw_header = []\n",
    "    for i in headers:\n",
    "        if i.startswith('20') == False:\n",
    "            j = 'tff_gw'\n",
    "            k = 'fpl_gw'\n",
    "        else:\n",
    "            tff_gw = md_map.loc[md_map['unique_dates']==i,'tff_gw'].values[0]\n",
    "            fpl_gw = md_map.loc[md_map['unique_dates']==i,'fpl_gw'].values[0]\n",
    "            j = str(tff_gw)\n",
    "            k = str(fpl_gw)\n",
    "        tff_gw_header.append(j)\n",
    "        fpl_gw_header.append(k)\n",
    "    md_header = []\n",
    "    for i in headers:\n",
    "        if i.startswith('20') == False:\n",
    "            j = 'matchday'\n",
    "        else:\n",
    "            md = md_map.loc[md_map['unique_dates']==i,'matchday'].values[0]\n",
    "            j = str(md)\n",
    "        md_header.append(j)\n",
    "    team_fixtures.columns=[tff_gw_header, fpl_gw_header, md_header, headers]\n",
    "\n",
    "\n",
    "    formatted_fixtures = team_fixtures.copy()\n",
    "    # Make color map dictionary and function\n",
    "    color_ts = team_priors[['short_team','h_gd', 'a_gd']].copy()\n",
    "    min_gd = min(color_ts['h_gd'].values.tolist() + color_ts['a_gd'].values.tolist())*2.3\n",
    "    max_gd = max(color_ts['h_gd'].values.tolist() + color_ts['a_gd'].values.tolist())#*1.8\n",
    "    norm = matplotlib.colors.Normalize(vmin=min_gd, vmax=max_gd, clip=True)\n",
    "    mapper = plt.cm.ScalarMappable(norm=norm, cmap=plt.cm.viridis_r)\n",
    "    color_ts['h_gd_color'] = color_ts['h_gd'].apply(lambda x: mcolors.to_hex(mapper.to_rgba(x)))\n",
    "    color_ts['a_gd_color'] = color_ts['a_gd'].apply(lambda x: mcolors.to_hex(mapper.to_rgba(x)))\n",
    "    h_teams = color_ts['short_team'].values.tolist()\n",
    "    a_teams = [team.lower() for team in h_teams]\n",
    "    teams = h_teams + a_teams\n",
    "    team_gd = color_ts['a_gd_color'].values.tolist() + color_ts['h_gd_color'].values.tolist()\n",
    "    color_dict = {teams[i]: team_gd[i] for i in range(len(teams))}\n",
    "    def color_col(col, pattern_map, default=''):\n",
    "        return np.select(\n",
    "            [col.str.contains(k, na=False) for k in pattern_map.keys()],\n",
    "            [f'background-color: {v}' for v in pattern_map.values()],\n",
    "            default=default\n",
    "        ).astype(str)\n",
    "    # Apply styles\n",
    "    formatted_fixtures = formatted_fixtures.style.apply(color_col,\n",
    "                                                pattern_map=color_dict\n",
    "                                                , subset=team_fixtures.columns[2:]\n",
    "                                                )\n",
    "    formatted_fixtures = formatted_fixtures.set_table_styles([\n",
    "                        {'selector': 'th.col_heading', 'props': 'text-align: left;'},\n",
    "                        {'selector': 'th.col_heading.level0', 'props': 'font-size: 1em;'},\n",
    "                        {'selector': 'td', 'props': 'text-align: center; font-weight: bold;'},\n",
    "                    ], overwrite=False)\n",
    "\n",
    "    return {'formatted_fixtures': formatted_fixtures, 'fixtures_data': fixtures_df, 'matchday_map': md_map, 'fix_permutation_dict': fix_permutation_dict, 'unformatted_fixtures': team_fixtures}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling Functions\n",
    "\n",
    "Generate dataframe of expected points values for a specified period, based on prior team and player level data. Calls fixture fixture generator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_team_data_gen():\n",
    "\n",
    "    team_data = pd.read_csv('../data/team_priors.csv', index_col=0)\n",
    "\n",
    "    return team_data\n",
    "\n",
    "def prior_player_data_gen(team_data):\n",
    "    \n",
    "    prior_player_data = pd.read_csv('../data/prior_player_data.csv')\n",
    "    pen_taker_override = pd.read_csv('../data/pen_taker_override.csv')\n",
    "    for index, row in pen_taker_override.iterrows():\n",
    "        if row['pen_share']==row['pen_share']:\n",
    "            prior_player_data.loc[prior_player_data['sky_id']==row['sky_id'], 'on_pens'] = row['pen_share']\n",
    "            print(str(row['reference_name']) + ' pen share overridden to ' + str(row['pen_share']))\n",
    "\n",
    "    try:\n",
    "        filepath = '../data/fplreview.csv'\n",
    "        fplreview = pd.read_csv(filepath)\n",
    "        fplreview = fplreview.rename(columns={'ID': 'fpl_id'})\n",
    "        review_xmins = True\n",
    "        print(f\"Using minutes from {filepath}\")\n",
    "    except:\n",
    "        review_xmins = False\n",
    "        print(f\"{filepath} not found, using default baseline minutes\") \n",
    "\n",
    "    if review_xmins:\n",
    "        # Get gw x_mins from fplreview file, and overwite\n",
    "        review_gw_list = []\n",
    "        for element in list(fplreview.columns.values):\n",
    "            if '_xMins' in element:\n",
    "                review_gw_list.append(element)\n",
    "        for element in list(prior_player_data.columns.values):\n",
    "            if element in review_gw_list:\n",
    "                prior_player_data = prior_player_data.drop(columns = [element])\n",
    "        prior_player_data = pd.merge(prior_player_data, fplreview.loc[:,['fpl_id'] + review_gw_list], on=['fpl_id'], how='inner')\n",
    "    else:\n",
    "        for gw in range(1,39):\n",
    "            prior_player_data[str(gw)+'_xMins'] = prior_player_data['bl_xmin']\n",
    "    \n",
    "    return {'prior_player_data':prior_player_data, 'review_xmins':review_xmins}\n",
    "\n",
    "def tff_xP_calc(sky_id, opp_team, prior_player_data, team_data, xMins, xP_breakdown=False, review_xmins=True):\n",
    "    player_data = prior_player_data.loc[prior_player_data['sky_id'] == sky_id].reset_index()\n",
    "    own_team = player_data.loc[0, 'short_team']\n",
    "    own_team_data = team_data.loc[team_data['short_team'] == own_team].reset_index()\n",
    "    opp_data = team_data.loc[team_data['short_team'] == opp_team.upper()].reset_index()\n",
    "    Pos = player_data.loc[0, 'sky_pos']\n",
    "    if opp_team.isupper() == True:\n",
    "        home_adv = own_team_data.loc[0, 'home_adv_g']\n",
    "        home_adv_pass = own_team_data.loc[0, 'home_adv_pass']\n",
    "    elif opp_team.islower() == True:\n",
    "        home_adv = 1/own_team_data.loc[0, 'home_adv_g']\n",
    "        home_adv_pass = 1/own_team_data.loc[0, 'home_adv_pass']\n",
    "    else:\n",
    "        home_adv = 1\n",
    "        home_adv_pass = 1\n",
    "    if Pos == 'GK':\n",
    "        k_G = 5\n",
    "        k_CS = 5\n",
    "        k_pCS = 2\n",
    "        k_2GC = -1\n",
    "    elif Pos == 'DEF':\n",
    "        k_G = 5\n",
    "        k_CS = 5\n",
    "        k_pCS = 2\n",
    "        k_2GC = -1\n",
    "    elif Pos == 'MID':\n",
    "        k_G = 5\n",
    "        k_CS = 0\n",
    "        k_pCS = 0\n",
    "        k_2GC = 0\n",
    "    else:\n",
    "        k_G = 5\n",
    "        k_CS = 0\n",
    "        k_pCS = 0\n",
    "        k_2GC = 0\n",
    "    k_1GC = 0\n",
    "    k_Start = 2\n",
    "    k_Sub = 1\n",
    "    k_A = 3\n",
    "    k_PenSv = 5\n",
    "    k_PenMiss = -2\n",
    "    k_Yc = -1\n",
    "    k_Rc = -3\n",
    "    k_OG = -3\n",
    "    k_Tk = 0.5\n",
    "    k_Sv = 0.5\n",
    "    x_90s = xMins/90\n",
    "    if review_xmins:\n",
    "        x_90s = xMins/95\n",
    "    p_start = (0.5)*(0.5 + np.cbrt((x_90s-0.5)/4)) + (0.5)*x_90s\n",
    "    StartxP = k_Start * p_start\n",
    "    SubxP = k_Sub * (1-p_start) * x_90s\n",
    "    GxP = k_G * player_data.loc[0, 'bl_npxg'] * opp_data.loc[0, 'bl_xg_against_k'] * x_90s * home_adv * player_data.loc[0, 'fin_skill']\n",
    "    AxP = k_A * player_data.loc[0, 'bl_a'] * opp_data.loc[0, 'bl_g_against_k'] * x_90s * home_adv\n",
    "    OGxP = k_OG * player_data.loc[0, 'bl_og'] * opp_data.loc[0, 'bl_og_against_k'] * x_90s / home_adv\n",
    "    PenScorexP = k_G * player_data.loc[0, 'on_pens'] * (player_data.loc[0, 'fin_skill'] * 0.78) * own_team_data.loc[0, 'bl_pk_att_for'] * opp_data.loc[0, 'bl_pk_att_against_k'] * x_90s * home_adv\n",
    "    PenMissxP = k_PenMiss * player_data.loc[0, 'on_pens'] * (1-player_data.loc[0, 'fin_skill'] * 0.78) * own_team_data.loc[0, 'bl_pk_att_for'] * opp_data.loc[0, 'bl_pk_att_against_k'] * x_90s * home_adv\n",
    "    if Pos == 'GK':\n",
    "        PenSvxP = k_PenSv * own_team_data.loc[0, 'bl_pk_att_against_k'] * 0.11 * opp_data.loc[0, 'bl_pk_att_for'] * x_90s / home_adv\n",
    "        SavexP = k_Sv * player_data.loc[0, 'bl_sv_per_sot'] * opp_data.loc[0, 'bl_sot_for'] * own_team_data.loc[0, 'bl_sot_against_k']  * x_90s / home_adv\n",
    "        TackxP = 0\n",
    "    if Pos == 'MID':\n",
    "        TackxP = k_Tk * player_data.loc[0, 'bl_tack'] * opp_data.loc[0, 'bl_tack_against_k'] * x_90s\n",
    "        PenSvxP = 0 \n",
    "        SavexP = 0 \n",
    "    else:\n",
    "        PenSvxP = 0    \n",
    "        TackxP = 0  \n",
    "        SavexP = 0  \n",
    "    YcxP = k_Yc * player_data.loc[0, 'bl_yc'] * opp_data.loc[0, 'bl_yc_against_k'] * x_90s\n",
    "    RcxP = k_Rc * player_data.loc[0, 'bl_rc'] * opp_data.loc[0, 'bl_yc_against_k'] * x_90s\n",
    "    mu_gc = own_team_data.loc[0, 'bl_g_against_k'] * opp_data.loc[0, 'bl_g_for'] / home_adv\n",
    "    full_CSxP = k_CS * poisson.cdf(k=0, mu=mu_gc*x_90s) * p_start * player_data.loc[0, 'bl_p_60_given_start'] \n",
    "    # below line is the chance of getting below 60 mins given a start, plus the chance of getting a substitute appearance (assumed below 60 mins)\n",
    "    p_mins_under_60 = p_start * (1-player_data.loc[0, 'bl_p_60_given_start']) + (1-p_start) * (1-player_data.loc[0, 'bl_p_90_given_start'])\n",
    "    partial_CSxP = k_pCS * poisson.cdf(k=0, mu=mu_gc) * p_mins_under_60\n",
    "    # this last line assumes you just want all clean sheet points summarized \n",
    "    CSxP = full_CSxP + partial_CSxP\n",
    "    GCxP = k_2GC * ((1 - poisson.cdf(k=1, mu=mu_gc*x_90s)) + (1 - poisson.cdf(k=2, mu=mu_gc*x_90s)) + (1 - poisson.cdf(k=3, mu=mu_gc*x_90s)) + (1 - poisson.cdf(k=4, mu=mu_gc*x_90s)))\n",
    "    xP = GxP + AxP + OGxP + PenScorexP + PenMissxP + PenSvxP + StartxP + SubxP + YcxP + RcxP + CSxP + GCxP + SavexP + TackxP\n",
    "    if xP_breakdown == True:\n",
    "        xP_breakdown = {'Actions': ['Start', 'Sub', 'Goal', 'Assist', 'Own Goal', 'Pen Goal', 'Pen Miss', 'Pen Save', 'Yellow Card', 'Red Card', 'Clean Sheet', 'Goal Conceded',\n",
    "                                    'Save', 'Tackle', 'TOTAL'],\n",
    "                        'xP': [StartxP, SubxP, GxP, AxP, OGxP, PenScorexP, PenMissxP, PenSvxP, YcxP, RcxP, CSxP, GCxP, SavexP, TackxP, xP]\n",
    "                        }\n",
    "        xP_breakdown = pd.DataFrame(xP_breakdown)\n",
    "        xP_breakdown = xP_breakdown.drop(xP_breakdown[xP_breakdown.xP == 0].index)\n",
    "        xP_breakdown.xP = round(xP_breakdown.xP,2)\n",
    "    return {'xP': xP, 'xP_breakdown': xP_breakdown}\n",
    "\n",
    "def generate_model_output(first_md=1, last_md=14, filename_suffix=None, custom_fixtures=None, teamsheet_boost=None):\n",
    "    schedule_name = 'sky_schedule'\n",
    "    if filename_suffix is not None:\n",
    "        schedule_name += filename_suffix\n",
    "    \n",
    "    if custom_fixtures is not None:\n",
    "        r = generate_ticker(custom_fixtures=custom_fixtures)\n",
    "    else:\n",
    "        r = generate_ticker()\n",
    "    md_map_2 = r['matchday_map']\n",
    "    sky_schedule_2 = r['fixtures_data']\n",
    "    formatted_fixtures = r['formatted_fixtures']\n",
    "    unformatted_fixtures = r['unformatted_fixtures']\n",
    "    headers = []\n",
    "    for i, x in enumerate(sky_schedule_2.columns.values.tolist()):\n",
    "        if x in md_map_2['unique_dates'].tolist():\n",
    "            h = md_map_2.loc[md_map_2['unique_dates'] == x, 'matchday'].values[0]\n",
    "            h = 'MD ' + str(h)\n",
    "            headers.append(h)\n",
    "        else:\n",
    "            headers.append(x)\n",
    "    sky_schedule_2.columns = headers\n",
    "\n",
    "    if str(last_md) == last_md:\n",
    "        if last_md > md_map_2['unique_dates'].tolist()[-1]:\n",
    "            last_md = md_map_2.loc[len(md_map_2)-1, 'matchday']\n",
    "        else:\n",
    "            for i, x in enumerate(md_map_2['unique_dates'].tolist()):\n",
    "                if last_md < x:\n",
    "                    last_md = md_map_2.loc[i, 'matchday'] - 1\n",
    "                    break\n",
    "    if str(last_md) == last_md:\n",
    "        last_md = md_map_2.loc[len(md_map_2)-1, 'matchday']\n",
    "\n",
    "    matchdays = range(first_md,last_md+1)\n",
    "    team_data = prior_team_data_gen()\n",
    "    player_data_results = prior_player_data_gen(team_data)\n",
    "    prior_player_data = player_data_results['prior_player_data']\n",
    "    review_xmins = player_data_results['review_xmins']\n",
    "    # prior_player_data = player_data['prior_player_data']\n",
    "\n",
    "    fpd = pd.merge(prior_player_data, sky_schedule_2, left_on='short_team', right_on='short_name', how='left')\n",
    "    \n",
    "    fixture_player_data = fpd.copy()\n",
    "    for i in range(first_md, last_md+1):\n",
    "        gw = md_map_2.loc[md_map_2['matchday']==i, 'fpl_gw'].values[0]\n",
    "        if f'{gw}_xMins' not in fixture_player_data.columns:\n",
    "            fixture_player_data[f'{gw}_xMins'] = fixture_player_data[f'{gw-1}_xMins']\n",
    "        fixture_player_data[f'MD {i} Game'] = fixture_player_data[f'MD {i}'].str.len() > 1.5\n",
    "        fixture_player_data[f'MD_{i}_xMins'] = fixture_player_data[f'{gw}_xMins'] * fixture_player_data[f'MD {i} Game']\n",
    "    players = fixture_player_data.index.tolist()\n",
    "    for p in players:\n",
    "        SKY_ID = fixture_player_data.loc[p, 'sky_id']\n",
    "        for m in matchdays:\n",
    "            xMins = fixture_player_data.loc[p, f'MD_{m}_xMins']\n",
    "            if xMins < 5:\n",
    "                xP = 0\n",
    "            else:\n",
    "                fix_string = fixture_player_data.loc[p, f'MD {m}']\n",
    "                if '\\n' in fix_string:\n",
    "                    xP = 0\n",
    "                    fix_list = fix_string.split('\\n')\n",
    "                    for i, x in enumerate(fix_list):\n",
    "                        r = tff_xP_calc(SKY_ID, x[:3], fixture_player_data, team_data, xMins, xP_breakdown=False, review_xmins=review_xmins)\n",
    "                        sub_xP = r['xP']\n",
    "                        if any(c.isdigit() for c in x):\n",
    "                            sub_xP = sub_xP * int(''.join(filter(str.isdigit, x))) / 100\n",
    "                        xP += sub_xP\n",
    "                else:\n",
    "                    r = tff_xP_calc(SKY_ID, fixture_player_data.loc[p, f'MD {m}'][:3], fixture_player_data, team_data, xMins, xP_breakdown=False)\n",
    "                    xP = r['xP']\n",
    "                    if any(c.isdigit() for c in fix_string):\n",
    "                        xP = xP * int(''.join(filter(str.isdigit, fix_string))) / 100\n",
    "                if teamsheet_boost is not None:\n",
    "                    if '!' in fix_string:\n",
    "                        xP = xP * (1+teamsheet_boost)\n",
    "            fixture_player_data.loc[p, f'MD_{m}_Pts'] = round(xP, 2)\n",
    "    skymodel_output = pd.concat([fixture_player_data.loc[:,['sky_id', 'fbref_player', 'short_team', 'sky_pos', 'tff_value']],\n",
    "                                    fixture_player_data.iloc[:,-(last_md-first_md+1):]],axis = 1)\n",
    "    skymodel_output['Total_Pts'] = skymodel_output.iloc[:, -(last_md-first_md+1):].sum(axis=1)\n",
    "    skymodel_output = skymodel_output.fillna(0)\n",
    "    filename = 'skymodel_output'\n",
    "    if filename_suffix is not None:\n",
    "        filename += filename_suffix\n",
    "    skymodel_output.to_csv(f'../data/{filename}.csv')\n",
    "    md_map_2.to_csv(f'../data/md_map.csv', index = False)\n",
    "\n",
    "    return {'skymodel_output':skymodel_output, 'formatted_fixtures':formatted_fixtures, 'md_map': md_map_2, 'unformatted_fixtures': unformatted_fixtures}\n",
    "\n",
    "def read_fpl_kid_model(filepath = '../data/fplkid.csv'):\n",
    "    fpl_kid = pd.read_csv(filepath).fillna(0)\n",
    "    fpl_kid = fpl_kid.rename(columns = {'Pos':'sky_pos', 'ID':'sky_id', 'BV':'tff_value'})\n",
    "    fpl_kid['Total_Pts'] = 0\n",
    "    for i in range(200):\n",
    "        fpl_kid = fpl_kid.rename(columns = {f'GD{i}_Pts':f'MD_{i}_Pts',f'GD{i}_xMins':f'MD_{i}_xMins'})\n",
    "        if f'MD_{i}_Pts' in fpl_kid.columns.tolist():\n",
    "            fpl_kid['Total_Pts'] += fpl_kid[f'MD_{i}_Pts']\n",
    "    fpl_kid = fpl_kid.drop(columns=['Name', 'SV', 'Team'])\n",
    "\n",
    "    fpl_kid['sky_pos'] = fpl_kid['sky_pos'].str.replace('G','GK')\n",
    "    fpl_kid['sky_pos'] = fpl_kid['sky_pos'].str.replace('F','FOR')\n",
    "    fpl_kid['sky_pos'] = fpl_kid['sky_pos'].str.replace('D','DEF')\n",
    "    fpl_kid['sky_pos'] = fpl_kid['sky_pos'].str.replace('M','MID')\n",
    "\n",
    "    player_data_merge = pd.read_csv('../data/prior_player_data.csv')\n",
    "    player_data_merge = player_data_merge[['sky_id','fbref_player','short_team']]\n",
    "\n",
    "    fpl_kid = pd.merge(left = fpl_kid, right = player_data_merge, on='sky_id', how='inner')\n",
    "    fpl_kid = fpl_kid.set_index('sky_id')\n",
    "    return fpl_kid\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Functions\n",
    "\n",
    "Generate optimal solution for team or analyze multiple simulated runs with noise, based on the model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'sky_pos': ['GK', 'DEF', 'MID', 'FOR'],\n",
    "        'squad_min_play': [1, 3, 3, 1],\n",
    "        'squad_max_play': [1, 5 ,5, 3]}\n",
    "type_data = pd.DataFrame(data, index=[1,2,3,4])\n",
    "\n",
    "def solve_tff_mp(initial_squad, input_data, md_map, next_md=1, last_md=10, \n",
    "                 ta_tot=40, ta_gw=5, objective='regular', decay_base=0.85, transfer_cost=7.5, \n",
    "                 exclusions=None, keeps=None, force_transfer_in=None, force_transfer_out=None, no_transfer_mds=None,\n",
    "                 apply_noise=False, seed_val=None, magnitude=1):\n",
    "    \n",
    "    if str(last_md) == last_md:\n",
    "        if last_md > md_map['unique_dates'].tolist()[-1]:\n",
    "            last_md = md_map.loc[len(md_map)-1, 'matchday']\n",
    "        else:\n",
    "            for i, x in enumerate(md_map['unique_dates'].tolist()):\n",
    "                if last_md < x:\n",
    "                    last_md = md_map.loc[i, 'matchday'] - 1\n",
    "                    break\n",
    "    if str(last_md) == last_md:\n",
    "        last_md = md_map.loc[len(md_map)-1, 'matchday']\n",
    "        \n",
    "    horizon = last_md + 1 - next_md\n",
    "    problem_name = f'sky_mp_h{horizon}_d1'\n",
    "    \n",
    "    # Sets\n",
    "    players = input_data.index.tolist()\n",
    "    element_types = type_data.index.tolist()\n",
    "    matchdays = list(range(next_md, next_md+horizon))\n",
    "    all_md = [next_md-1] + matchdays\n",
    "    \n",
    "    first_gw = int(md_map.loc[md_map['matchday']==next_md, 'tff_gw'].values[0])\n",
    "    last_gw = int(md_map.loc[md_map['matchday']==last_md, 'tff_gw'].values[0])\n",
    "    gameweeks = list(range(first_gw,last_gw+1))\n",
    "    gw_transfer_allowance = {w: 5 for w in gameweeks}\n",
    "    gw_transfer_allowance[first_gw] = min(ta_gw,5)\n",
    "\n",
    "    if apply_noise:\n",
    "        rng = np.random.default_rng(seed = seed_val)\n",
    "        input_data['Total_Pts'] = 0\n",
    "        player_df = pd.read_csv('../data/prior_player_data.csv')\n",
    "        player_df = player_df[['sky_id', 'noise_factor']]\n",
    "        input_data = pd.merge(input_data,player_df,on='sky_id').set_index('sky_id')\n",
    "        for m in matchdays:\n",
    "            noise = input_data[f'MD_{m}_Pts'] * 0.035 * rng.standard_normal(size = len(input_data)) * magnitude * input_data['noise_factor']\n",
    "            input_data[f'MD_{m}_Pts'] = input_data[f'MD_{m}_Pts'] + round(noise,2)\n",
    "            input_data['Total_Pts'] += input_data[f'MD_{m}_Pts']\n",
    "\n",
    "    # Model\n",
    "    model = so.Model(name = 'multi_period')\n",
    "\n",
    "    # Variables\n",
    "    squad = model.add_variables(players, all_md, name='squad', vartype=so.binary)\n",
    "    transfer_in = model.add_variables(players, matchdays, name='transfer_in', vartype=so.binary)\n",
    "    transfer_out = model.add_variables(players, matchdays, name='transfer_out', vartype=so.binary)\n",
    "    \n",
    "    # Dictionaries\n",
    "    squad_type_count = {(t,d): so.expr_sum(squad[p,d] for p in players if input_data.loc[p, 'sky_pos'] == type_data.loc[t, 'sky_pos']) for t in element_types for d in matchdays}\n",
    "    player_value = (input_data['tff_value']).to_dict()\n",
    "    bought_amount = {d: so.expr_sum(player_value[p] * transfer_in[p,d] for p in players) for d in matchdays}\n",
    "    sold_amount = {d: so.expr_sum(player_value[p] * transfer_out[p,d] for p in players) for d in matchdays}\n",
    "    squad_value = {d: so.expr_sum(player_value[p] * squad[p,d] for p in players) for d in matchdays}\n",
    "    points_player_day = {(p,d): input_data.loc[p, f'MD_{d}_Pts'] for p in players for d in matchdays}\n",
    "    squad_count = {d: so.expr_sum(squad[p, d] for p in players) for d in matchdays}\n",
    "    \n",
    "    total_number_of_transfers = so.expr_sum(transfer_out[p,d] for p in players for d in matchdays) \n",
    "\n",
    "    md_number_of_transfers = {d: so.expr_sum(transfer_out[p,d] for p in players) for d in matchdays}        \n",
    "    gw_number_of_transfers = {w: so.expr_sum(md_number_of_transfers[d] for d in matchdays if int(md_map.loc[md_map['matchday']==d, 'tff_gw'].values[0]) == w) for w in gameweeks}\n",
    "    \n",
    "    # Initial Conditions\n",
    "    if initial_squad is not None:\n",
    "        model.add_constraints((squad[p, next_md-1] == 1 for p in initial_squad), name='initial_squad_players')\n",
    "        model.add_constraints((squad[p, next_md-1] == 0 for p in players if p not in initial_squad), name='initial_squad_others')\n",
    "    # Constraints: squad\n",
    "    model.add_constraints((squad_count[d] == 11 for d in matchdays), name='squad_count')    \n",
    "    # Constraints: formation and budget\n",
    "    model.add_constraints((squad_type_count[t,d] == [type_data.loc[t, 'squad_min_play'], type_data.loc[t, 'squad_max_play']] for t in element_types for d in matchdays), name='valid_formation_1')\n",
    "    model.add_constraints((squad_type_count[2,d]-squad_type_count[4,d] <= 3.5 for d in matchdays), name='valid_formation_2')\n",
    "    model.add_constraints((squad_value[d] <= 50 for d in matchdays), name='squad_budget')\n",
    "    # Constraints: transfers\n",
    "    model.add_constraints((squad[p,d] == squad[p,d-1] + transfer_in[p,d] - transfer_out[p,d] for p in players for d in matchdays), name='squad_transfer_rel')\n",
    "    model.add_constraint(total_number_of_transfers <= min(ta_tot,40), name = 'transfer_allowance')\n",
    "    model.add_constraints((gw_number_of_transfers[w] <= gw_transfer_allowance[w] for w in gameweeks), name = 'gw_transfer_allowance')\n",
    "    if no_transfer_mds is not None:\n",
    "        model.add_constraints((md_number_of_transfers[m] == 0 for m in no_transfer_mds), name='no_transfer_matchdays')\n",
    "    # Constraints: specified players\n",
    "    # Force Exclude\n",
    "    if exclusions is not None:\n",
    "        model.add_constraints((squad[e, d] == 0 for e in exclusions for d in matchdays), name = 'force_exclude_players')\n",
    "    # Force Keep\n",
    "    if keeps is not None:\n",
    "        model.add_constraints((squad[e, d] == 1 for e in keeps for d in matchdays), name = 'force_keep_players')\n",
    "    # Force transfer in\n",
    "    if force_transfer_in is not None:\n",
    "        model.add_constraints((squad[force_transfer_in[e][0], force_transfer_in[e][1]] == 1 for e in list(range(len(force_transfer_in)))), name = 'force_transfer_in_players')\n",
    "        model.add_constraints((squad[force_transfer_in[e][0], force_transfer_in[e][1]-1] == 0 for e in list(range(len(force_transfer_in)))), name = 'force_transfer_in_players_2')\n",
    "    # Force transfer out\n",
    "    if force_transfer_out is not None:\n",
    "        model.add_constraints((squad[force_transfer_out[e][0], force_transfer_out[e][1]] == 0 for e in list(range(len(force_transfer_out)))), name = 'force_transfer_out_players')\n",
    "        model.add_constraints((squad[force_transfer_out[e][0], force_transfer_out[e][1]-1] == 1 for e in list(range(len(force_transfer_out)))), name = 'force_transfer_out_players_2')\n",
    "    \n",
    "    # Objective\n",
    "    md_xp = {d: so.expr_sum(points_player_day[p,d] * (squad[p,d]) for p in players) for d in matchdays}\n",
    "    if objective == 'regular':\n",
    "        total_xp = so.expr_sum(md_xp[d] for d in matchdays) - total_number_of_transfers*transfer_cost\n",
    "        model.set_objective(-total_xp, sense='N', name='total_regular_xp') \n",
    "    else:\n",
    "        # total_xp = so.expr_sum(md_xp[d] * pow(decay_base, d-next_md) for d in matchdays) - total_number_of_transfers*transfer_cost\n",
    "        days_elapsed0 = md_map.loc[md_map['matchday']==next_md,'days_elapsed'].values[0]\n",
    "        # Convert weekly decay to daily\n",
    "        decay_base = decay_base ** (1/7)\n",
    "        total_xp = so.expr_sum(md_xp[d] * pow(decay_base, md_map.loc[md_map['matchday']==d,'days_elapsed'].values[0]-days_elapsed0) for d in matchdays) - total_number_of_transfers*transfer_cost\n",
    "        model.set_objective(-total_xp, sense='N', name='total_decay_xp')\n",
    "    \n",
    "    # Solve Step\n",
    "    model.export_mps(filename='skyoutput.mps')\n",
    "    command = f'cbc skyoutput.mps solve solu {problem_name}_sol.txt'\n",
    "    # !{command}\n",
    "    os.system(command)\n",
    "    # Read the solution back to the file\n",
    "    with open(f'{problem_name}_sol.txt', 'r') as f:\n",
    "        for v in model.get_variables():\n",
    "            v.set_value(0)\n",
    "        for line in f:\n",
    "            if 'objective value' in line:\n",
    "                continue\n",
    "            words = line.split()\n",
    "            var = model.get_variable(words[1])\n",
    "            var.set_value(float(words[2]))\n",
    "            \n",
    "    # (OLD) Generate a dataframe to display the solution \n",
    "    picks = []\n",
    "    for d in matchdays:\n",
    "        for p in players:\n",
    "            if squad[p,d].get_value() + transfer_out[p,d].get_value() > 0.5:\n",
    "                lp = input_data.loc[p]\n",
    "                is_transfer_in = 1 if transfer_in[p,d].get_value() > 0.5 else 0\n",
    "                is_transfer_out = 1 if transfer_out[p,d].get_value() > 0.5 else 0\n",
    "                picks.append([\n",
    "                    int(md_map.loc[md_map['matchday']==d, 'tff_gw'].values[0]), d, lp['fbref_player'], lp['sky_pos'], lp['short_team'], lp['tff_value'], round(points_player_day[p,d], 2), is_transfer_in, is_transfer_out\n",
    "                ])\n",
    "    picks_df = pd.DataFrame(picks, columns=['tff_gw','matchday','name', 'pos', 'team', 'value', 'xP', 'transfer_in', 'transfer_out'])#.sort_values(by=['matchday'])\n",
    "    picks_df.loc[picks_df['matchday'] == next_md, 'transfer_in'] = 0\n",
    "    \n",
    "    total_xp = round(so.expr_sum(points_player_day[p,d] * (squad[p,d]) for p in players for d in matchdays).get_value(), 2)\n",
    "    \n",
    "    # Generate a better dataframe to display the solution\n",
    "    plan = []\n",
    "    for t in element_types:\n",
    "        for p in players:\n",
    "            if so.expr_sum(squad[p,d] + transfer_out[p,d] for d in matchdays).get_value() >= 0.5 and input_data.loc[p, 'sky_pos'] == type_data.loc[t, 'sky_pos']:\n",
    "                lp = input_data.loc[p]\n",
    "                player_info = [p, lp['short_team'], lp['sky_pos'], lp['tff_value'], lp['fbref_player']]\n",
    "                for d in matchdays:\n",
    "                    if squad[p,d].get_value() > 0.5:\n",
    "                        score = f'{round(points_player_day[p,d], 2)}'\n",
    "                    else:\n",
    "                        score = ''\n",
    "                    player_info.append(score)\n",
    "                plan.append(player_info)\n",
    "    columns = ['ID','Team', 'Pos','Value','Name']\n",
    "    for d in matchdays:\n",
    "        # w = int(md_map.loc[md_map['matchday']==d, 'tff_gw'].values[0])\n",
    "        columns.append(f\"{d}\")\n",
    "    plan_df = pd.DataFrame(plan, columns=columns)\n",
    "    plan_df = plan_df.replace(['0.0'],'-')\n",
    "    plan_df = plan_df.replace(['0.0c'],'-')\n",
    "    itb_row = ['','','','','ITB']\n",
    "    for d in matchdays:\n",
    "        itb = 50 - squad_value[d].get_value()\n",
    "        itb_row.append(itb)\n",
    "    plan_df.loc[len(plan_df)] = itb_row\n",
    "\n",
    "    # make dataframe to record the players in a simulation\n",
    "    plan = []\n",
    "    if apply_noise:\n",
    "        for t in element_types:\n",
    "            for p in players:\n",
    "                if so.expr_sum(squad[p,d] + transfer_out[p,d] for d in matchdays).get_value() >= 0.5 and input_data.loc[p, 'sky_pos'] == type_data.loc[t, 'sky_pos']:\n",
    "                    lp = input_data.loc[p]\n",
    "                    player_info = [p, lp['short_team'], lp['sky_pos'], lp['tff_value'], lp['fbref_player']]\n",
    "                    for d in matchdays:\n",
    "                        if squad[p,d].get_value() > 0.5:\n",
    "                            score = 1\n",
    "                        else:\n",
    "                            score = 0\n",
    "                        player_info.append(score)\n",
    "                    plan.append(player_info)\n",
    "        columns = ['ID','Team', 'Pos','Value','Name']\n",
    "        for d in matchdays:\n",
    "            # w = int(md_map.loc[md_map['matchday']==d, 'tff_gw'].values[0])\n",
    "            columns.append(f\"{d}\")\n",
    "        players_in_sim = pd.DataFrame(plan, columns=columns)\n",
    "    else:\n",
    "        players_in_sim = None\n",
    "    \n",
    "    tff_gw_header = []\n",
    "    fpl_gw_header = []\n",
    "    for i in columns:\n",
    "        if i == 'Name':\n",
    "            j = 'tff_gw'\n",
    "            k = 'fpl_gw'\n",
    "        elif not str(i)[0].isdigit():\n",
    "            j = ''\n",
    "            k = ''\n",
    "        else:\n",
    "            tff_gw = md_map.loc[md_map['matchday']==int(i),'tff_gw'].values[0]\n",
    "            fpl_gw = md_map.loc[md_map['matchday']==int(i),'fpl_gw'].values[0]\n",
    "            j = str(tff_gw)\n",
    "            k = str(fpl_gw)\n",
    "        tff_gw_header.append(j)\n",
    "        fpl_gw_header.append(k)\n",
    "    plan_df.columns=[tff_gw_header, fpl_gw_header, columns]\n",
    "\n",
    "    transfers_made = int(total_number_of_transfers.get_value())\n",
    "    \n",
    "    return{'model': model, 'picks': picks_df, 'total_xp': total_xp, 'plan': plan_df, 'transfers_made': transfers_made, 'players_in_sim': players_in_sim}\n",
    "\n",
    "# Produce sensitivity analysis with noise\n",
    "def solve_tff_mp_noise(initial_squad, input_data, md_map, next_md=1, last_md=7, \n",
    "                       ta_tot=40, ta_gw=5, objective='regular', decay_base=0.85, transfer_cost=5, \n",
    "                       exclusions=None, keeps=None, force_transfer_in=None, force_transfer_out=None, no_transfer_mds=None,\n",
    "                       seed_val=None, nsims=5, magnitude=1):\n",
    "    transfer_sum = 0\n",
    "\n",
    "    baseline_projection_df = input_data\n",
    "\n",
    "    for i in range(nsims):\n",
    "        print(f\"Running sim {i+1} of {nsims}...\")\n",
    "        input_data = baseline_projection_df.copy()\n",
    "        results = solve_tff_mp(initial_squad=initial_squad, input_data=input_data, md_map=md_map, next_md=next_md, last_md=last_md, \n",
    "                    ta_tot=ta_tot, ta_gw=ta_gw, objective=objective, decay_base=decay_base, transfer_cost=transfer_cost,\n",
    "                    exclusions=exclusions, keeps=keeps, force_transfer_in=force_transfer_in, force_transfer_out=force_transfer_out, no_transfer_mds=no_transfer_mds,\n",
    "                    apply_noise=True, seed_val=seed_val, magnitude=magnitude)\n",
    "        players_in_sim = results['players_in_sim']\n",
    "        if i == 0:\n",
    "            sensitivity_df = players_in_sim\n",
    "        else:\n",
    "            rows_to_add = []\n",
    "            for index, row in results['players_in_sim'].iterrows():\n",
    "                if row['ID'] in sensitivity_df['ID'].tolist():\n",
    "                    sensitivity_df.loc[sensitivity_df['ID']==row['ID'], '1':] = sensitivity_df.loc[sensitivity_df['ID']==row['ID'], '1':] + row['1':]\n",
    "                    continue\n",
    "                else: \n",
    "                    rows_to_add.append(row)\n",
    "            if len(rows_to_add) > 0:\n",
    "                rows_to_add_df = pd.concat(rows_to_add, axis=1).T\n",
    "                sensitivity_df = pd.concat([sensitivity_df, rows_to_add_df], ignore_index=True)\n",
    "        clear_output(wait=True)\n",
    "        transfer_sum += results['transfers_made']\n",
    "    avg_trf = transfer_sum/nsims\n",
    "    sensitivity_df.loc[:, '1':] = sensitivity_df.loc[:, '1':] * 100 / nsims\n",
    "    sensitivity_df.loc[:, '1':] = sensitivity_df.loc[:, '1':].astype(int)\n",
    "\n",
    "    # Sort the dataframe by initial team and position\n",
    "    sensitivity_df['max_ocuurences'] = 0\n",
    "    sensitivity_df['init_team'] = 0\n",
    "    sensitivity_df['pos_code'] = 0\n",
    "    for index, row in sensitivity_df.iterrows():\n",
    "        if row['Pos'] == 'GK':\n",
    "            sensitivity_df.loc[index,'pos_code'] = 1\n",
    "        elif row['Pos'] == 'DEF':\n",
    "            sensitivity_df.loc[index,'pos_code'] = 2\n",
    "        elif row['Pos'] == 'MID':\n",
    "            sensitivity_df.loc[index,'pos_code'] = 3\n",
    "        else:\n",
    "            sensitivity_df.loc[index,'pos_code'] = 4\n",
    "        if row['ID'] in initial_squad:\n",
    "            sensitivity_df.loc[index,'init_team'] = 1\n",
    "    sensitivity_df = sensitivity_df.sort_values(by=['pos_code', 'init_team'], ascending=[True, False])\n",
    "    sensitivity_df.drop(['max_ocuurences', 'init_team', 'pos_code'], axis=1, inplace=True)\n",
    "    \n",
    "    columns = sensitivity_df.columns.values.tolist()\n",
    "\n",
    "    tff_gw_header = []\n",
    "    fpl_gw_header = []\n",
    "    for i in columns:\n",
    "        if i == 'Name':\n",
    "            j = 'tff_gw'\n",
    "            k = 'fpl_gw'\n",
    "        elif not str(i)[0].isdigit():\n",
    "            j = ''\n",
    "            k = ''\n",
    "        else:\n",
    "            tff_gw = md_map.loc[md_map['matchday'] == int(i), 'tff_gw'].values[0]\n",
    "            fpl_gw = md_map.loc[md_map['matchday'] == int(i), 'fpl_gw'].values[0]\n",
    "            j = str(tff_gw)\n",
    "            k = str(fpl_gw)\n",
    "        tff_gw_header.append(j)\n",
    "        fpl_gw_header.append(k)\n",
    "    sensitivity_df.columns=[tff_gw_header, fpl_gw_header, columns]\n",
    "\n",
    "    sens = sensitivity_df.copy()\n",
    "    sens = sens.style.background_gradient(cmap=\"RdPu\", subset=sensitivity_df.columns[5:]).format(precision=1)\n",
    "    # sens.set_properties(**{'text-align': 'left'})\n",
    "    sens = sens.set_table_styles([\n",
    "                        {'selector': 'th.col_heading', 'props': 'text-align: left;'},\n",
    "                        {'selector': 'th.col_heading.level0', 'props': 'font-size: 1em;'},\n",
    "                        {'selector': 'td', 'props': 'text-align: center; font-weight: bold;'},\n",
    "                    ], overwrite=False)\n",
    "                \n",
    "    return {'sensitivity_df': sens, 'avg_trf': avg_trf, 'sensitivity_df_unformatted': sensitivity_df}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Commands\n",
    "Some example commands are given in the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To just see the upcoming fixtures:\n",
    "r0 = generate_ticker()\n",
    "r0['formatted_fixtures']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see a breakdown of EV for a given player and fixture:\n",
    "prior_player_data = pd.read_csv('../data/prior_player_data.csv')\n",
    "team_data = pd.read_csv('../data/team_priors.csv')\n",
    "# Find a players sky_id in prior_player_data.csv\n",
    "# opp_team is case sensitive, uppercase and lowercase implying home and away respectively\n",
    "# The below example is Mbeumo at home to Luton\n",
    "r1 = tff_xP_calc(sky_id=895, opp_team='LUT', prior_player_data=prior_player_data, team_data=team_data, xMins=81, xP_breakdown=True)\n",
    "r1['xP_breakdown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To generate player EV from the fixtures:\n",
    "# Change player or team underlyings as you see fit in prior_player_data.csv and team_priors.csv\n",
    "# Penalty takers can be overridden in pen_taker_override.csv\n",
    "# Adding an fplreview.csv to the data folder will let the model use its xMins. Alternatively, edit bl_xmins in prior_player_data.csv to manually override them \n",
    "\n",
    "# Example custom fixtures dataframe to add, move, or remove fixtures and assign probabilities of occuring\n",
    "# Leave 'custom_fixtures=None' to keep the fixtures as they are on the PL site\n",
    "df = pd.DataFrame(columns=('home_team', 'away_team', 'dates', 'probabilities'))\n",
    "df.loc[len(df)] = ['FOR', 'SHU', ['2023-12-06'], [1]]\n",
    "\n",
    "# Generate fixture ticker and player EV\n",
    "# Setting \"teamsheet_boost\" to a positive decimal (e.g. 0.05) will boost the EV of players for whom the teamsheet will be released before the deadline\n",
    "# Set the last matchday, last_md, as an integer, or a date as a string in the format 'YYYY-mm-dd'\n",
    "r2 = generate_model_output(first_md=1, last_md=42, filename_suffix=None, custom_fixtures=None, teamsheet_boost=0)\n",
    "display(r2['formatted_fixtures'])\n",
    "# display(r2['unformatted_fixtures'])\n",
    "display(r2['skymodel_output'].sort_values(by=['Total_Pts'], ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To generate optimal team and plan:\n",
    "skymodel_output = pd.read_csv('../data/skymodel_output.csv').set_index('sky_id').fillna(0)\n",
    "# To use FPL Kid data, download the 'Telegraph Fantasy EV - CSV' google sheet as fplkid.csv, add to data folder, and uncomment the following line\n",
    "#skymodel_output = read_fpl_kid_model(filepath='../data/fplkid.csv')\n",
    "# Cut off players with low EV to save solve time\n",
    "ev_cutoff = skymodel_output['Total_Pts'].max() * 0.2\n",
    "skymodel_output = skymodel_output[skymodel_output['Total_Pts'] > ev_cutoff]\n",
    "\n",
    "md_map = pd.read_csv('../data/md_map.csv')\n",
    "\n",
    "# List all the sky IDs of all players to include in the initial squad (or leave empty), see prior_player_data.csv for reference\n",
    "team = []\n",
    "exclusions = []\n",
    "keeps = []\n",
    "\n",
    "# Change how much you penalize the solver for making a transfer, alternatively set a hard limit by changing the total transfer allowance: ta_tot\n",
    "transfer_cost =6.5\n",
    "\n",
    "# Generate optimal plan\n",
    "r3 = solve_tff_mp(initial_squad=team, input_data=skymodel_output, md_map=md_map, next_md=1, last_md=42,\n",
    "                  ta_tot=40, ta_gw=5, objective='regular', decay_base=1, transfer_cost=transfer_cost,\n",
    "                  exclusions=exclusions, keeps=keeps, force_transfer_in=None, force_transfer_out=None, no_transfer_mds=None,\n",
    "                  apply_noise=False)\n",
    "display(r3['plan'])\n",
    "print(f\"Total xP: {r3['total_xp']}\")\n",
    "print(f\"Total transfers made: {r3['transfers_made']}, transfer cost: {transfer_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run multiple solves with noise:\n",
    "skymodel_output = pd.read_csv('../data/skymodel_output.csv').set_index('sky_id').fillna(0)\n",
    "# To use FPL Kid data, download the 'Telegraph Fantasy EV - CSV' google sheet as fplkid.csv, add to data folder, and uncomment the following line\n",
    "#skymodel_output = read_fpl_kid_model(filepath='../data/fplkid.csv')\n",
    "ev_cutoff = skymodel_output['Total_Pts'].max() * 0\n",
    "skymodel_output = skymodel_output[skymodel_output['Total_Pts'] > ev_cutoff]\n",
    "md_map = pd.read_csv('../data/md_map.csv')\n",
    "\n",
    "team = []\n",
    "exclusions = []\n",
    "transfer_cost = 10\n",
    "# Choose a number of simulations to run\n",
    "nsims = 5\n",
    "# Choose the relative magnitude of applied noise (1 is standard)\n",
    "magnitude = 1\n",
    "\n",
    "# Generate sensitivity analysis\n",
    "r4 = solve_tff_mp_noise(initial_squad=team, input_data=skymodel_output, md_map=md_map, next_md=1, last_md=42,\n",
    "                        ta_tot=40, ta_gw=5, objective='regular', decay_base=1, transfer_cost=transfer_cost,\n",
    "                        exclusions=exclusions, keeps=None, force_transfer_in=None, force_transfer_out=None, no_transfer_mds=None,\n",
    "                        seed_val=None, nsims=nsims, magnitude=magnitude)\n",
    "display(r4['sensitivity_df'])\n",
    "# display(r4['sensitivity_df_unformatted'])\n",
    "print(f\"Number of sims: {nsims}, average transfers made: {r4['avg_trf']}, with cost: {transfer_cost}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "92da1a170ecb0018a71137dc8b8687270834efb85fe22800f1b77b06a6422852"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
